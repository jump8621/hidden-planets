{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade\n",
    "#upgraded on 1/23/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib\n",
    "# said requirement already satisfied 1/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "# Sklearn Evaluation Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, precision_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# Import packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Sklearn Evaluation Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, precision_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# Visualizes all the columns\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>-0.11600</td>\n",
       "      <td>874.8</td>\n",
       "      <td>35.5</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2</td>\n",
       "      <td>5455</td>\n",
       "      <td>81</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5.126</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0.03410</td>\n",
       "      <td>-0.03410</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-171.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>3.92</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>31.04</td>\n",
       "      <td>-10.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5853</td>\n",
       "      <td>158</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>-0.00537</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>33.46</td>\n",
       "      <td>8.50</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>668.95</td>\n",
       "      <td>-230.35</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5805</td>\n",
       "      <td>157</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0.04200</td>\n",
       "      <td>-0.04200</td>\n",
       "      <td>603.3</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>874.33</td>\n",
       "      <td>-314.24</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1</td>\n",
       "      <td>6031</td>\n",
       "      <td>169</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>-0.06730</td>\n",
       "      <td>686.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>420.33</td>\n",
       "      <td>-136.70</td>\n",
       "      <td>40.2</td>\n",
       "      <td>2</td>\n",
       "      <td>6046</td>\n",
       "      <td>189</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  koi_time0bk_err2  koi_impact  koi_impact_err1  \\\n",
       "0          0.003520         -0.003520       0.586            0.059   \n",
       "1          0.000581         -0.000581       0.969            5.126   \n",
       "2          0.000115         -0.000115       1.276            0.115   \n",
       "3          0.001130         -0.001130       0.701            0.235   \n",
       "4          0.001900         -0.001900       0.762            0.139   \n",
       "\n",
       "   koi_impact_err2  koi_duration  koi_duration_err1  koi_duration_err2  \\\n",
       "0           -0.443       4.50700            0.11600           -0.11600   \n",
       "1           -0.077       1.78220            0.03410           -0.03410   \n",
       "2           -0.092       2.40641            0.00537           -0.00537   \n",
       "3           -0.478       1.65450            0.04200           -0.04200   \n",
       "4           -0.532       3.14020            0.06730           -0.06730   \n",
       "\n",
       "   koi_depth  koi_depth_err1  koi_depth_err2  koi_prad  koi_prad_err1  \\\n",
       "0      874.8            35.5           -35.5      2.83           0.32   \n",
       "1    10829.0           171.0          -171.0     14.60           3.92   \n",
       "2     8079.2            12.8           -12.8     33.46           8.50   \n",
       "3      603.3            16.9           -16.9      2.75           0.88   \n",
       "4      686.0            18.7           -18.7      2.77           0.90   \n",
       "\n",
       "   koi_prad_err2  koi_teq  koi_insol  koi_insol_err1  koi_insol_err2  \\\n",
       "0          -0.19      443       9.11            2.87           -1.62   \n",
       "1          -1.31      638      39.30           31.04          -10.49   \n",
       "2          -2.83     1395     891.96          668.95         -230.35   \n",
       "3          -0.35     1406     926.16          874.33         -314.24   \n",
       "4          -0.30     1160     427.65          420.33         -136.70   \n",
       "\n",
       "   koi_model_snr  koi_tce_plnt_num  koi_steff  koi_steff_err1  koi_steff_err2  \\\n",
       "0           25.8                 2       5455              81             -81   \n",
       "1           76.3                 1       5853             158            -176   \n",
       "2          505.6                 1       5805             157            -174   \n",
       "3           40.9                 1       6031             169            -211   \n",
       "4           40.2                 2       6046             189            -232   \n",
       "\n",
       "   koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  \\\n",
       "0      4.467           0.064          -0.096     0.927          0.105   \n",
       "1      4.544           0.044          -0.176     0.868          0.233   \n",
       "2      4.564           0.053          -0.168     0.791          0.201   \n",
       "3      4.438           0.070          -0.210     1.046          0.334   \n",
       "4      4.486           0.054          -0.229     0.972          0.315   \n",
       "\n",
       "   koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0         -0.061  291.93423  48.141651      15.347  \n",
       "1         -0.078  297.00482  48.134129      15.436  \n",
       "2         -0.067  285.53461  48.285210      15.597  \n",
       "3         -0.133  288.75488  48.226200      15.509  \n",
       "4         -0.105  296.28613  48.224670      15.714  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "cl_df = df.dropna()\n",
    "cl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.koi_tce_plnt_num\n",
    "# koi_fpflag_nt\tkoi_fpflag_ss\tkoi_fpflag_co\tkoi_fpflag_ec\tkoi_period\tkoi_period_err1\tkoi_period_err2\tkoi_time0bk\tkoi_time0bk_err1\tkoi_time0bk_err2\tkoi_impact\tkoi_impact_err1\tkoi_impact_err2\tkoi_duration\tkoi_duration_err1\tkoi_duration_err2\tkoi_depth\tkoi_depth_err1\tkoi_depth_err2\tkoi_prad\tkoi_prad_err1\tkoi_prad_err2\tkoi_teq\tkoi_insol\tkoi_insol_err1\tkoi_insol_err2\tkoi_model_snr\tkoi_steff\tkoi_steff_err1\tkoi_steff_err2\tkoi_slogg\tkoi_slogg_err1\tkoi_slogg_err2\tkoi_srad\tkoi_srad_err1\tkoi_srad_err2\tra\tdec\tkoi_kepmag\n",
    "# [20               25               18               24                5            17           26           30                  29          13                 4                   6            9               28             33              31                   19                7           37            36                8            34           35       15          11             10                3                 1              1                 12           21               14           16       1           23             22             27   2      32]\n",
    "selected_features = cl_df[['koi_tce_plnt_num', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'ra', 'dec', 'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2', 'koi_model_snr', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_kepmag', 'koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2', 'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2']]\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6991, 40) (6991,)\n"
     ]
    }
   ],
   "source": [
    "X = selected_features\n",
    "y = cl_df['koi_disposition']\n",
    "print(X.shape, y.shape)\n",
    "# .values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_steff_err1</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_depth_err1</th>\n",
       "      <th>koi_depth_err2</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_prad_err1</th>\n",
       "      <th>koi_prad_err2</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_duration_err1</th>\n",
       "      <th>koi_duration_err2</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_impact_err1</th>\n",
       "      <th>koi_impact_err2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>293.05801</td>\n",
       "      <td>45.248821</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>4932</td>\n",
       "      <td>145</td>\n",
       "      <td>-148</td>\n",
       "      <td>12.6</td>\n",
       "      <td>4.777</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>15.801</td>\n",
       "      <td>99.673478</td>\n",
       "      <td>3.463000e-04</td>\n",
       "      <td>-3.463000e-04</td>\n",
       "      <td>219.334830</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>2496.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>-264.0</td>\n",
       "      <td>576.14</td>\n",
       "      <td>30.44</td>\n",
       "      <td>-31.62</td>\n",
       "      <td>262</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>-0.1790</td>\n",
       "      <td>11.6846</td>\n",
       "      <td>1.516</td>\n",
       "      <td>-10.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>290.28094</td>\n",
       "      <td>45.464260</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>4920</td>\n",
       "      <td>146</td>\n",
       "      <td>-146</td>\n",
       "      <td>303.8</td>\n",
       "      <td>4.664</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>15.653</td>\n",
       "      <td>0.592244</td>\n",
       "      <td>9.000000e-08</td>\n",
       "      <td>-9.000000e-08</td>\n",
       "      <td>131.654831</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>3992.4</td>\n",
       "      <td>18.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>1551</td>\n",
       "      <td>1361.22</td>\n",
       "      <td>410.79</td>\n",
       "      <td>-331.29</td>\n",
       "      <td>1.3860</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>-0.0156</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>301.04239</td>\n",
       "      <td>45.022888</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>5874</td>\n",
       "      <td>158</td>\n",
       "      <td>-176</td>\n",
       "      <td>220.3</td>\n",
       "      <td>4.338</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>14.039</td>\n",
       "      <td>9.991625</td>\n",
       "      <td>5.360000e-06</td>\n",
       "      <td>-5.360000e-06</td>\n",
       "      <td>137.447816</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>3450.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>-19.2</td>\n",
       "      <td>38.93</td>\n",
       "      <td>10.98</td>\n",
       "      <td>-7.31</td>\n",
       "      <td>907</td>\n",
       "      <td>160.14</td>\n",
       "      <td>132.50</td>\n",
       "      <td>-66.64</td>\n",
       "      <td>3.8552</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288.32785</td>\n",
       "      <td>38.627621</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>6078</td>\n",
       "      <td>122</td>\n",
       "      <td>-134</td>\n",
       "      <td>535.1</td>\n",
       "      <td>4.346</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>13.944</td>\n",
       "      <td>178.412990</td>\n",
       "      <td>3.100000e-05</td>\n",
       "      <td>-3.100000e-05</td>\n",
       "      <td>218.225235</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>37510.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>33.24</td>\n",
       "      <td>5.85</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>361</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>2.9298</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.67938</td>\n",
       "      <td>50.241299</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>5676</td>\n",
       "      <td>85</td>\n",
       "      <td>-68</td>\n",
       "      <td>134.8</td>\n",
       "      <td>4.347</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>10.961</td>\n",
       "      <td>45.294223</td>\n",
       "      <td>5.600000e-05</td>\n",
       "      <td>-5.600000e-05</td>\n",
       "      <td>138.678725</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>477.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>524</td>\n",
       "      <td>17.75</td>\n",
       "      <td>3.21</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>6.8300</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_tce_plnt_num  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "4002                 2              0              0              1   \n",
       "4246                 1              0              1              0   \n",
       "548                  1              0              1              1   \n",
       "3953                 1              0              1              0   \n",
       "2362                 1              0              0              0   \n",
       "\n",
       "      koi_fpflag_ec         ra        dec  koi_srad  koi_srad_err1  \\\n",
       "4002              0  293.05801  45.248821     0.492          0.026   \n",
       "4246              0  290.28094  45.464260     0.591          0.045   \n",
       "548               0  301.04239  45.022888     1.096          0.309   \n",
       "3953              0  288.32785  38.627621     1.148          0.202   \n",
       "2362              0  285.67938  50.241299     1.044          0.057   \n",
       "\n",
       "      koi_srad_err2  koi_steff  koi_steff_err1  koi_steff_err2  koi_model_snr  \\\n",
       "4002         -0.027       4932             145            -148           12.6   \n",
       "4246         -0.045       4920             146            -146          303.8   \n",
       "548          -0.206       5874             158            -176          220.3   \n",
       "3953         -0.124       6078             122            -134          535.1   \n",
       "2362         -0.042       5676              85             -68          134.8   \n",
       "\n",
       "      koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_kepmag  koi_period  \\\n",
       "4002      4.777           0.040          -0.027      15.801   99.673478   \n",
       "4246      4.664           0.056          -0.032      15.653    0.592244   \n",
       "548       4.338           0.153          -0.187      14.039    9.991625   \n",
       "3953      4.346           0.084          -0.126      13.944  178.412990   \n",
       "2362      4.347           0.030          -0.030      10.961   45.294223   \n",
       "\n",
       "      koi_period_err1  koi_period_err2  koi_time0bk  koi_time0bk_err1  \\\n",
       "4002     3.463000e-04    -3.463000e-04   219.334830          0.002300   \n",
       "4246     9.000000e-08    -9.000000e-08   131.654831          0.000124   \n",
       "548      5.360000e-06    -5.360000e-06   137.447816          0.000445   \n",
       "3953     3.100000e-05    -3.100000e-05   218.225235          0.000127   \n",
       "2362     5.600000e-05    -5.600000e-05   138.678725          0.000987   \n",
       "\n",
       "      koi_time0bk_err2  koi_depth  koi_depth_err1  koi_depth_err2  koi_prad  \\\n",
       "4002         -0.002300     2496.0           264.0          -264.0    576.14   \n",
       "4246         -0.000124     3992.4            18.2           -18.2      6.77   \n",
       "548          -0.000445     3450.5            19.2           -19.2     38.93   \n",
       "3953         -0.000127    37510.0           100.0          -100.0     33.24   \n",
       "2362         -0.000987      477.1             3.7            -3.7      2.26   \n",
       "\n",
       "      koi_prad_err1  koi_prad_err2  koi_teq  koi_insol  koi_insol_err1  \\\n",
       "4002          30.44         -31.62      262       1.11            0.27   \n",
       "4246           0.51          -0.52     1551    1361.22          410.79   \n",
       "548           10.98          -7.31      907     160.14          132.50   \n",
       "3953           5.85          -3.59      361       4.00            2.00   \n",
       "2362           0.12          -0.09      524      17.75            3.21   \n",
       "\n",
       "      koi_insol_err2  koi_duration  koi_duration_err1  koi_duration_err2  \\\n",
       "4002           -0.23        0.9680             0.1790            -0.1790   \n",
       "4246         -331.29        1.3860             0.0156            -0.0156   \n",
       "548           -66.64        3.8552             0.0235            -0.0235   \n",
       "3953           -1.09        2.9298             0.0124            -0.0124   \n",
       "2362           -2.17        6.8300             0.0343            -0.0343   \n",
       "\n",
       "      koi_impact  koi_impact_err1  koi_impact_err2  \n",
       "4002     11.6846            1.516          -10.450  \n",
       "4246      0.9860            0.048           -0.054  \n",
       "548       1.2560            0.258           -0.119  \n",
       "3953      0.9360            0.093           -0.046  \n",
       "2362      0.0250            0.333           -0.025  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# import tensorflow\n",
    "# tensorflow.keras.__version__\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaler = X_scaler.transform(X_train)\n",
    "X_test_scaler = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaler, y_train)\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(y_train)\n",
    "# encoded_y_train = label_encoder.transform(y_train)\n",
    "# encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# encoded_y_train\n",
    "\n",
    "# rf.fit(X_train_scaler, encoded_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8439824527942018\n",
      "Testing Data Score: 0.8415331807780321\n"
     ]
    }
   ],
   "source": [
    "# training_score = rf.score(X_train_scaler, encoded_y_train)\n",
    "# testing_score = rf.score(X_test_scaler, encoded_y_test)\n",
    "training_score = model.score(X_train_scaler, y_train)\n",
    "testing_score = model.score(X_test_scaler, y_test)\n",
    "# print(f\"Training Data Score: {model.score(X_train_minmax, encoded_y_train)}\")\n",
    "# print(f\"Testing Data Score: {model.score(X_test_minmax, encoded_y_test)}\")\n",
    "print(f\"Training Data Score: {training_score}\")\n",
    "print(f\"Testing Data Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature_importance , rfe, backwards elimination, etc\n",
    "# importances = model.feature_importances_\n",
    "# importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pplanets = list(selected_features.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.008441246791460718, 'koi_srad_err2'),\n",
       " (0.008597853556272123, 'koi_slogg'),\n",
       " (0.00874310980062724, 'koi_slogg_err1'),\n",
       " (0.00900651400683086, 'koi_srad'),\n",
       " (0.010204592386861404, 'koi_steff'),\n",
       " (0.010487223487471803, 'koi_kepmag'),\n",
       " (0.010496216185108613, 'koi_slogg_err2'),\n",
       " (0.011239680951216894, 'koi_impact_err2'),\n",
       " (0.011409239824832707, 'koi_impact_err1'),\n",
       " (0.011636157241563215, 'dec'),\n",
       " (0.011767075525728846, 'koi_srad_err1'),\n",
       " (0.01214583464379168, 'ra'),\n",
       " (0.012483331139022337, 'koi_insol_err2'),\n",
       " (0.013305245257352695, 'koi_depth_err1'),\n",
       " (0.013428949356057592, 'koi_time0bk'),\n",
       " (0.013596587124042813, 'koi_insol'),\n",
       " (0.013664116575229835, 'koi_depth_err2'),\n",
       " (0.016114105697859486, 'koi_teq'),\n",
       " (0.016937789155165306, 'koi_insol_err1'),\n",
       " (0.016950386059882614, 'koi_period_err1'),\n",
       " (0.01874235742308141, 'koi_impact'),\n",
       " (0.01927050801526513, 'koi_period_err2'),\n",
       " (0.020764783705136066, 'koi_depth'),\n",
       " (0.022055806405841427, 'koi_duration'),\n",
       " (0.02308785701794663, 'koi_period'),\n",
       " (0.024220179964613228, 'koi_time0bk_err2'),\n",
       " (0.02457405842248483, 'koi_time0bk_err1'),\n",
       " (0.028413897839350288, 'koi_steff_err2'),\n",
       " (0.03290075739059276, 'koi_prad_err2'),\n",
       " (0.032992251425447545, 'koi_prad_err1'),\n",
       " (0.03303839495661001, 'koi_duration_err1'),\n",
       " (0.033566222563292385, 'koi_steff_err1'),\n",
       " (0.03425190304444843, 'koi_fpflag_ec'),\n",
       " (0.03456973710961651, 'koi_duration_err2'),\n",
       " (0.0461107073909787, 'koi_prad'),\n",
       " (0.05550226593641993, 'koi_model_snr'),\n",
       " (0.06390940916975246, 'koi_fpflag_ss'),\n",
       " (0.10230140373309311, 'koi_fpflag_nt'),\n",
       " (0.1090722437196505, 'koi_fpflag_co')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # We can sort the features by their importance\n",
    "# sorted(zip(rf.feature_importances_, Pplanets), reverse=False)\n",
    "# should probably try with koi_impac_err1 and 'koi_srad_err1') back in the selected features - since the testing data score \n",
    "# went down when the the imputs were correct through out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes insignificant variables and retrain models with significant features\n",
    "selected_features = cl_df[['koi_tce_plnt_num', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'ra', 'dec', 'koi_steff_err1', 'koi_steff_err2', 'koi_model_snr', 'koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2', 'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2']]\n",
    "#,,[(0.008441246791460718, 'koi_srad_err2'), (0.008597853556272123, 'koi_slogg'), #  (0.00874310980062724, 'koi_slogg_err1'),\n",
    "#  (0.00900651400683086, 'koi_srad'), (0.010204592386861404, 'koi_steff'), #  (0.010487223487471803, 'koi_kepmag'), 'koi_slogg_err2',\n",
    "#  (0.010496216185108613, 'koi_slogg_err2'),\n",
    "\n",
    "# [(0.01410490578983619, 'koi_srad_err2'),\n",
    "#  (0.015052134927837428, 'koi_slogg_err1'),\n",
    "#  (0.015755639380292074, 'koi_srad'),\n",
    "#  (0.015814925469765838, 'koi_slogg'),\n",
    "#  (0.016685934965700318, 'koi_steff'),\n",
    "#  (0.017343393315965013, 'koi_kepmag'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6991, 32) (6991,)\n"
     ]
    }
   ],
   "source": [
    "X = selected_features\n",
    "y = cl_df['koi_disposition']\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# data = X.copy().values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaler = X_scaler.transform(X_train)\n",
    "X_test_scaler = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaler, y_train)\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(y_train)\n",
    "# encoded_y_train = label_encoder.transform(y_train)\n",
    "# encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# encoded_y_train\n",
    "\n",
    "# rf.fit(X_train_scaler, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8474156017547205\n",
      "Testing Data Score: 0.8375286041189931\n"
     ]
    }
   ],
   "source": [
    "# training_score = rf.score(X_train_scaler, encoded_y_train)\n",
    "# testing_score = rf.score(X_test_scaler, encoded_y_test)\n",
    "training_score = model.score(X_train_scaler, y_train)\n",
    "testing_score = model.score(X_test_scaler, y_test)\n",
    "# print(f\"Training Data Score: {model.score(X_train_minmax, encoded_y_train)}\")\n",
    "# print(f\"Testing Data Score: {model.score(X_test_minmax, encoded_y_test)}\")\n",
    "print(f\"Training Data Score: {training_score}\")\n",
    "print(f\"Testing Data Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\jump1\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True False False False False  True False\n",
      " False False False False]\n",
      "Feature Ranking: [28 20 25 18 24  5 17 26 30 31 13  4  6  9 29 34 32 19  7 38 37  8 35 36\n",
      " 15 11 10  3  1  1 12 21 14 16  1 23 22 27  2 33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#koi_tce_plnt_num koi_fpflag_nt\tkoi_fpflag_ss\tkoi_fpflag_co\tkoi_fpflag_ec\tkoi_period\tkoi_period_err1\tkoi_period_err2\tkoi_time0bk\tkoi_time0bk_err1\tkoi_time0bk_err2\tkoi_impact\tkoi_impact_err1\tkoi_impact_err2\tkoi_duration\tkoi_duration_err1\tkoi_duration_err2\tkoi_depth\tkoi_depth_err1\tkoi_depth_err2\tkoi_prad\tkoi_prad_err1\tkoi_prad_err2\tkoi_teq\tkoi_insol\tkoi_insol_err1\tkoi_insol_err2\tkoi_model_snr\t koi_steff\tkoi_steff_err1\tkoi_steff_err2\tkoi_slogg\tkoi_slogg_err1\tkoi_slogg_err2\tkoi_srad\tkoi_srad_err1\tkoi_srad_err2\tra\tdec\tkoi_kepmag\n",
    "# [20               25               18               24                5            17           26           30                  29          13                 4                   6            9               28             33              31                   19                7           37            36                8            34           35               15                 11             10                3                1              1               12           21            14           16           1             23               22          27   2      32]\n",
    "    \n",
    "selected_features2 = cl_df[['koi_period', 'dec', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2', 'koi_depth_err1', 'koi_prad_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_steff', 'koi_steff_err1', 'koi_srad', 'koi_insol_err1', 'koi_steff_err2', 'koi_time0bk_err2', 'koi_slogg_err1', 'koi_insol', 'koi_slogg_err2', 'koi_period_err1', 'koi_depth', 'koi_fpflag_nt', 'koi_slogg', 'koi_srad_err2', 'koi_srad_err1', 'koi_fpflag_ec', 'koi_fpflag_ss', 'koi_period_err2', 'ra', 'koi_duration', 'koi_time0bk_err1', 'koi_time0bk', 'koi_duration_err1', 'koi_kepmag', 'koi_tce_plnt_num']]\n",
    "# selected_features = cl_df[[,, 'koi_fpflag_co', 'koi_slogg_err1',,,, , 'koi_depth', 'koi_depth_err2', 'koi_prad', 'koi_prad_err2', 'koi_teq', 'koi_duration_err2',\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6991, 34) (6991,)\n"
     ]
    }
   ],
   "source": [
    "X = selected_features2\n",
    "y = cl_df['koi_disposition']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaler = X_scaler.transform(X_train)\n",
    "X_test_scaler = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7901964524127408\n",
      "Testing Data Score: 0.7814645308924485\n"
     ]
    }
   ],
   "source": [
    "training_score = model.score(X_train_scaler, y_train)\n",
    "testing_score = model.score(X_test_scaler, y_test)\n",
    "# print(f\"Training Data Score: {model.score(X_train_minmax, encoded_y_train)}\")\n",
    "# print(f\"Testing Data Score: {model.score(X_test_minmax, encoded_y_test)}\")\n",
    "print(f\"Training Data Score: {training_score}\")\n",
    "print(f\"Testing Data Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=SVC(kernel='linear'),\n",
      "             param_grid={'C': [1, 5, 10, 50],\n",
      "                         'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
      "             verbose=3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)\n",
    "\n",
    "\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ..............................C=1, gamma=0.0001; total time=   0.4s\n",
      "[CV 2/5] END ..............................C=1, gamma=0.0001; total time=   0.3s\n",
      "[CV 3/5] END ..............................C=1, gamma=0.0001; total time=   0.3s\n",
      "[CV 4/5] END ..............................C=1, gamma=0.0001; total time=   0.3s\n",
      "[CV 5/5] END ..............................C=1, gamma=0.0001; total time=   0.3s\n",
      "[CV 1/5] END ..............................C=1, gamma=0.0005; total time=   0.3s\n",
      "[CV 2/5] END ..............................C=1, gamma=0.0005; total time=   0.3s\n",
      "[CV 3/5] END ..............................C=1, gamma=0.0005; total time=   0.3s\n",
      "[CV 4/5] END ..............................C=1, gamma=0.0005; total time=   0.4s\n",
      "[CV 5/5] END ..............................C=1, gamma=0.0005; total time=   0.2s\n",
      "[CV 1/5] END ...............................C=1, gamma=0.001; total time=   0.2s\n",
      "[CV 2/5] END ...............................C=1, gamma=0.001; total time=   0.2s\n",
      "[CV 3/5] END ...............................C=1, gamma=0.001; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=1, gamma=0.001; total time=   0.3s\n",
      "[CV 5/5] END ...............................C=1, gamma=0.001; total time=   0.3s\n",
      "[CV 1/5] END ...............................C=1, gamma=0.005; total time=   0.3s\n",
      "[CV 2/5] END ...............................C=1, gamma=0.005; total time=   0.3s\n",
      "[CV 3/5] END ...............................C=1, gamma=0.005; total time=   0.2s\n",
      "[CV 4/5] END ...............................C=1, gamma=0.005; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=1, gamma=0.005; total time=   0.2s\n",
      "[CV 1/5] END ..............................C=5, gamma=0.0001; total time=   0.3s\n",
      "[CV 2/5] END ..............................C=5, gamma=0.0001; total time=   0.2s\n",
      "[CV 3/5] END ..............................C=5, gamma=0.0001; total time=   0.3s\n",
      "[CV 4/5] END ..............................C=5, gamma=0.0001; total time=   0.2s\n",
      "[CV 5/5] END ..............................C=5, gamma=0.0001; total time=   0.3s\n",
      "[CV 1/5] END ..............................C=5, gamma=0.0005; total time=   0.3s\n",
      "[CV 2/5] END ..............................C=5, gamma=0.0005; total time=   0.3s\n",
      "[CV 3/5] END ..............................C=5, gamma=0.0005; total time=   0.3s\n",
      "[CV 4/5] END ..............................C=5, gamma=0.0005; total time=   0.2s\n",
      "[CV 5/5] END ..............................C=5, gamma=0.0005; total time=   0.3s\n",
      "[CV 1/5] END ...............................C=5, gamma=0.001; total time=   0.4s\n",
      "[CV 2/5] END ...............................C=5, gamma=0.001; total time=   0.3s\n",
      "[CV 3/5] END ...............................C=5, gamma=0.001; total time=   0.3s\n",
      "[CV 4/5] END ...............................C=5, gamma=0.001; total time=   0.3s\n",
      "[CV 5/5] END ...............................C=5, gamma=0.001; total time=   0.3s\n",
      "[CV 1/5] END ...............................C=5, gamma=0.005; total time=   0.3s\n",
      "[CV 2/5] END ...............................C=5, gamma=0.005; total time=   0.2s\n",
      "[CV 3/5] END ...............................C=5, gamma=0.005; total time=   0.4s\n",
      "[CV 4/5] END ...............................C=5, gamma=0.005; total time=   0.2s\n",
      "[CV 5/5] END ...............................C=5, gamma=0.005; total time=   0.3s\n",
      "[CV 1/5] END .............................C=10, gamma=0.0001; total time=   0.3s\n",
      "[CV 2/5] END .............................C=10, gamma=0.0001; total time=   0.4s\n",
      "[CV 3/5] END .............................C=10, gamma=0.0001; total time=   0.4s\n",
      "[CV 4/5] END .............................C=10, gamma=0.0001; total time=   0.2s\n",
      "[CV 5/5] END .............................C=10, gamma=0.0001; total time=   0.3s\n",
      "[CV 1/5] END .............................C=10, gamma=0.0005; total time=   0.3s\n",
      "[CV 2/5] END .............................C=10, gamma=0.0005; total time=   0.3s\n",
      "[CV 3/5] END .............................C=10, gamma=0.0005; total time=   0.3s\n",
      "[CV 4/5] END .............................C=10, gamma=0.0005; total time=   0.3s\n",
      "[CV 5/5] END .............................C=10, gamma=0.0005; total time=   0.3s\n",
      "[CV 1/5] END ..............................C=10, gamma=0.001; total time=   0.3s\n",
      "[CV 2/5] END ..............................C=10, gamma=0.001; total time=   0.4s\n",
      "[CV 3/5] END ..............................C=10, gamma=0.001; total time=   0.3s\n",
      "[CV 4/5] END ..............................C=10, gamma=0.001; total time=   0.3s\n",
      "[CV 5/5] END ..............................C=10, gamma=0.001; total time=   0.3s\n",
      "[CV 1/5] END ..............................C=10, gamma=0.005; total time=   0.3s\n",
      "[CV 2/5] END ..............................C=10, gamma=0.005; total time=   0.3s\n",
      "[CV 3/5] END ..............................C=10, gamma=0.005; total time=   0.3s\n",
      "[CV 4/5] END ..............................C=10, gamma=0.005; total time=   0.3s\n",
      "[CV 5/5] END ..............................C=10, gamma=0.005; total time=   0.3s\n",
      "[CV 1/5] END .............................C=50, gamma=0.0001; total time=   0.4s\n",
      "[CV 2/5] END .............................C=50, gamma=0.0001; total time=   0.3s\n",
      "[CV 3/5] END .............................C=50, gamma=0.0001; total time=   0.4s\n",
      "[CV 4/5] END .............................C=50, gamma=0.0001; total time=   0.3s\n",
      "[CV 5/5] END .............................C=50, gamma=0.0001; total time=   0.3s\n",
      "[CV 1/5] END .............................C=50, gamma=0.0005; total time=   0.4s\n",
      "[CV 2/5] END .............................C=50, gamma=0.0005; total time=   0.4s\n",
      "[CV 3/5] END .............................C=50, gamma=0.0005; total time=   0.4s\n",
      "[CV 4/5] END .............................C=50, gamma=0.0005; total time=   0.3s\n",
      "[CV 5/5] END .............................C=50, gamma=0.0005; total time=   0.4s\n",
      "[CV 1/5] END ..............................C=50, gamma=0.001; total time=   0.5s\n",
      "[CV 2/5] END ..............................C=50, gamma=0.001; total time=   0.4s\n",
      "[CV 3/5] END ..............................C=50, gamma=0.001; total time=   0.5s\n",
      "[CV 4/5] END ..............................C=50, gamma=0.001; total time=   0.3s\n",
      "[CV 5/5] END ..............................C=50, gamma=0.001; total time=   0.4s\n",
      "[CV 1/5] END ..............................C=50, gamma=0.005; total time=   0.4s\n",
      "[CV 2/5] END ..............................C=50, gamma=0.005; total time=   0.4s\n",
      "[CV 3/5] END ..............................C=50, gamma=0.005; total time=   0.5s\n",
      "[CV 4/5] END ..............................C=50, gamma=0.005; total time=   0.5s\n",
      "[CV 5/5] END ..............................C=50, gamma=0.005; total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10, 50],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model utils GridSearchgri\n",
    "# import random\n",
    "# random.seed(0)\n",
    "# from sklearn.utils import parallel_backend\n",
    "\n",
    "# with parallel_backend('threading'):\n",
    "grid.fit(X_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 0.0001}\n",
      "0.8821285630080264\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.879\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RFC = grid.best_estimator_\n",
    "print('Test accuracy: %.3f' % RFC.score(X_test_scaler, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JuliannPezzullo-SVC.sav']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib \n",
    "filename = 'JuliannPezzullo-SVC.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=load('JuliannPezzullo-RF3.sav') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[237 180   5]\n",
      " [ 82 353  15]\n",
      " [  2   0 874]]\n",
      "Normalized confusion matrix\n",
      "[[0.56 0.43 0.01]\n",
      " [0.18 0.78 0.03]\n",
      " [0.   0.   1.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn import svm, datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# import some data to play with\n",
    "# iris = datasets.load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "# class_names = iris.target_names\n",
    "\n",
    "\n",
    "X = selected_features\n",
    "y= cl_df['koi_disposition'].values.reshape(-1,1)\n",
    "class_names = ['CONFIRMED', 'FALSE POSITIVE', 'CANDIDATE']\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# # Run classifier, using a model that is too regularized (C too low) to see\n",
    "# # the impact on the results\n",
    "# classifier = svm.SVC(kernel='linear', C=0.01).fit(X_train, y_train)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(model, X_test_scaler, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('JuliannPezzullo-RF3.sav') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_model.score(X_test_scaler, encoded_y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
